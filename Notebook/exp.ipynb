{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Google Sheets CSV export URL\n",
    "url = \"https://docs.google.com/spreadsheets/d/1H-b3MA0fEEHH7eP-fut1sYHlRsjc5i8ZadReynrw0m0/export?format=csv&gid=167401221\"\n",
    "\n",
    "# Read into DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Preview\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ New rows detected: 1\n",
      "     PassengerId  Survived  Pclass            Name   Sex   Age  SibSp  Parch  \\\n",
      "840          841         1       1  Md Kamruzzaman  male  33.0    0.0      0   \n",
      "\n",
      "    Ticket  Fare Cabin Embarked  \n",
      "840  15000  30.0   E29        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Step 1: Define URL of the Google Sheet ---\n",
    "url = \"https://docs.google.com/spreadsheets/d/1H-b3MA0fEEHH7eP-fut1sYHlRsjc5i8ZadReynrw0m0/export?format=csv&gid=167401221\"\n",
    "\n",
    "# --- Step 2: Load the full data ---\n",
    "df = pd.read_csv(url)\n",
    "current_len = len(df)\n",
    "\n",
    "# --- Step 3: Define log file path ---\n",
    "log_file = \"data_load.log\"\n",
    "\n",
    "# --- Step 4: Get last loaded row count from the last line ---\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, 'r') as log:\n",
    "        lines = log.readlines()\n",
    "        if lines:\n",
    "            last_line = lines[-1]\n",
    "            last_len = int(last_line.strip().split(\" - \")[-1])\n",
    "        else:\n",
    "            last_len = 0\n",
    "else:\n",
    "    last_len = 0  # First time load\n",
    "\n",
    "# --- Step 5: Extract only new rows ---\n",
    "if current_len > last_len:\n",
    "    new_rows = df.iloc[last_len:current_len]\n",
    "    print(f\"✅ New rows detected: {len(new_rows)}\")\n",
    "    print(new_rows)\n",
    "else:\n",
    "    print(\"✅ No new rows found.\")\n",
    "    new_rows = pd.DataFrame()  # Empty DataFrame if nothing new\n",
    "\n",
    "# --- Step 6: Append current row count and timestamp to the log ---\n",
    "now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "with open(log_file, 'a') as log:\n",
    "    log.write(f\"{now} - {current_len}\\n\")\n",
    "\n",
    "# --- Step 7: Save new rows to a CSV (optional) ---\n",
    "if not new_rows.empty:\n",
    "    new_rows.to_csv(\"new_rows.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ No new rows found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Step 1: Define URL of the Google Sheet ---\n",
    "url = \"https://docs.google.com/spreadsheets/d/1H-b3MA0fEEHH7eP-fut1sYHlRsjc5i8ZadReynrw0m0/export?format=csv&gid=167401221\"\n",
    "\n",
    "# --- Step 2: Load the full data ---\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# --- Step 3: Transform column names to lowercase ---\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "current_len = len(df)\n",
    "\n",
    "# --- Step 4: Define log file path ---\n",
    "log_file = \"data_load.log\"\n",
    "\n",
    "# --- Step 5: Get last loaded row count from the last valid line ---\n",
    "last_len = 0\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, 'r') as log:\n",
    "        lines = [line.strip() for line in log.readlines() if line.strip()]\n",
    "        if lines:\n",
    "            for line in reversed(lines):\n",
    "                try:\n",
    "                    last_len = int(line.split(\" - \")[-1])\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    continue  # Skip malformed lines\n",
    "\n",
    "# --- Step 6: Extract only new rows ---\n",
    "if current_len > last_len:\n",
    "    new_rows = df.iloc[last_len:current_len]\n",
    "    print(f\"✅ New rows detected: {len(new_rows)}\")\n",
    "    print(new_rows)\n",
    "else:\n",
    "    print(\"✅ No new rows found.\")\n",
    "    new_rows = pd.DataFrame()\n",
    "\n",
    "# --- Step 7: Append current row count and timestamp to the log ---\n",
    "now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "with open(log_file, 'a') as log:\n",
    "    log.write(f\"{now} - {current_len}\\n\")\n",
    "\n",
    "# --- Step 8: Save new rows to a CSV (optional) ---\n",
    "if not new_rows.empty:\n",
    "    new_rows.to_csv(\"new_rows.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Step 1: Define URL of the Google Sheet ---\n",
    "#url = \"https://docs.google.com/spreadsheets/d/1H-b3MA0fEEHH7eP-fut1sYHlRsjc5i8ZadReynrw0m0/export?format=csv&gid=167401221\"\n",
    "url = \"https://drive.google.com/file/d/1Bm9nP2KJE7XMf6tnbGjD1fUVZOcJFor4/view?usp=drive_link\"\n",
    "# --- Step 2: Load the full data ---\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# --- Step 3: Transform column names to lowercase ---\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "current_len = len(df)\n",
    "\n",
    "# --- Step 4: Define log file path ---\n",
    "log_file = \"data_load.log\"\n",
    "\n",
    "# --- Step 5: Get last loaded row count from the last valid line ---\n",
    "last_len = 0\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, 'r') as log:\n",
    "        lines = [line.strip() for line in log.readlines() if line.strip()]\n",
    "        if lines:\n",
    "            for line in reversed(lines):\n",
    "                try:\n",
    "                    last_len = int(line.split(\" - \")[-1])\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "# --- Step 6: Extract only new rows ---\n",
    "if current_len > last_len:\n",
    "    new_rows = df.iloc[last_len:current_len]\n",
    "    print(f\"✅ New rows detected: {len(new_rows)}\")\n",
    "    print(new_rows)\n",
    "else:\n",
    "    print(\"✅ No new rows found.\")\n",
    "    new_rows = pd.DataFrame()\n",
    "\n",
    "# --- Step 7: Append current row count and timestamp to the log ---\n",
    "now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "with open(log_file, 'a') as log:\n",
    "    log.write(f\"{now} - {current_len}\\n\")\n",
    "\n",
    "# --- Step 8: Save new rows to a CSV (optional) ---\n",
    "if not new_rows.empty:\n",
    "    new_rows.to_csv(\"new_rows.csv\", index=False)\n",
    "\n",
    "    # --- Step 9: Insert into SQLite database ---\n",
    "    db_path = \"taxi_data.db\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    new_rows.to_sql(\"titanic_data\", conn, if_exists=\"append\", index=False)\n",
    "    conn.close()\n",
    "    print(f\"✅ Inserted {len(new_rows)} new rows into database: {db_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ New rows detected: 1\n",
      "     passengerid  survived  pclass name  sex  age  sibsp  parch ticket  fare  \\\n",
      "856          857         0     NaN  NaN  NaN  NaN    NaN    NaN    NaN   NaN   \n",
      "\n",
      "    cabin embarked  \n",
      "856   NaN      NaN  \n",
      "✅ Inserted 1 new rows into PostgreSQL table: titanic_data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# --- Step 1: Define URL of the Google Sheet ---\n",
    "url = \"https://drive.google.com/file/d/1Bm9nP2KJE7XMf6tnbGjD1fUVZOcJFor4/view?usp=drive_link\"\n",
    "\n",
    "# --- Step 2: Load the full data ---\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# --- Step 3: Transform column names to lowercase ---\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "current_len = len(df)\n",
    "\n",
    "# --- Step 4: Define log file path ---\n",
    "log_file = \"data_load.log\"\n",
    "\n",
    "# --- Step 5: Get last loaded row count from the last valid line ---\n",
    "last_len = 0\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, 'r') as log:\n",
    "        lines = [line.strip() for line in log.readlines() if line.strip()]\n",
    "        if lines:\n",
    "            for line in reversed(lines):\n",
    "                try:\n",
    "                    last_len = int(line.split(\" - \")[-1])\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "# --- Step 6: Extract only new rows ---\n",
    "if current_len > last_len:\n",
    "    new_rows = df.iloc[last_len:current_len]\n",
    "    print(f\"✅ New rows detected: {len(new_rows)}\")\n",
    "    print(new_rows)\n",
    "else:\n",
    "    print(\"✅ No new rows found.\")\n",
    "    new_rows = pd.DataFrame()\n",
    "\n",
    "# --- Step 7: Append current row count and timestamp to the log ---\n",
    "now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "with open(log_file, 'a') as log:\n",
    "    log.write(f\"{now} - {current_len}\\n\")\n",
    "\n",
    "# --- Step 8: Save new rows to a CSV (optional) ---\n",
    "if not new_rows.empty:\n",
    "    new_rows.to_csv(\"new_rows.csv\", index=False)\n",
    "\n",
    "    # --- Step 9: Insert into PostgreSQL ---\n",
    "    postgresql_host = \"localhost\"\n",
    "    postgresql_user = \"postgres\"\n",
    "    postgresql_password = \"123456\"\n",
    "    postgresql_db = \"titanic\"\n",
    "    postgresql_port = \"5433\"\n",
    "\n",
    "    table_name = \"taxi_data\"\n",
    "\n",
    "    # Create connection engine\n",
    "    engine = create_engine(\n",
    "        f\"postgresql+psycopg2://{postgresql_user}:{postgresql_password}@{postgresql_host}:{postgresql_port}/{postgresql_db}\"\n",
    "    )\n",
    "\n",
    "    # Insert into table\n",
    "    new_rows.to_sql(table_name, engine, if_exists=\"append\", index=False)\n",
    "    print(f\"✅ Inserted {len(new_rows)} new rows into PostgreSQL table: {table_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'titanic_data' created and data inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "url = \"https://docs.google.com/spreadsheets/d/1H-b3MA0fEEHH7eP-fut1sYHlRsjc5i8ZadReynrw0m0/export?format=csv&gid=167401221\"\n",
    "df = pd.read_csv(url)\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "postgresql_host = \"localhost\"\n",
    "postgresql_user = \"postgres\"\n",
    "postgresql_password = \"123456\"\n",
    "postgresql_db = \"titanic\"\n",
    "postgresql_port = \"5433\"\n",
    "table_name = \"titanic_data\"\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{postgresql_user}:{postgresql_password}@{postgresql_host}:{postgresql_port}/{postgresql_db}\"\n",
    ")\n",
    "\n",
    "# Replace table if it exists, this will create it freshly\n",
    "df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "print(f\"Table '{table_name}' created and data inserted successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic_mlops_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
